{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e542b104",
   "metadata": {},
   "source": [
    "# Policy Gradient Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c69d9856",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import time, matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b0a8e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 327\n",
    "rng = np.random.default_rng(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8ecb42",
   "metadata": {},
   "source": [
    "## REINFORCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32e58bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8b0853",
   "metadata": {},
   "source": [
    "### Póliza Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b146c2",
   "metadata": {},
   "source": [
    "El entorno de CartPole-v1 tiene un espacio de acciones discreto:\n",
    "\n",
    "| Acción | Descripción                       |\n",
    "|--------|-----------------------------------|\n",
    "| 0      | Mover el carro a la izquierda     |\n",
    "| 1      | Mover el carro a la derecha       |\n",
    "\n",
    "Por lo tanto, se usará `softmax` como **póliza parametrizable**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75916907",
   "metadata": {},
   "source": [
    "La función `softmax` parametrizable es:\n",
    "\n",
    "$$\n",
    "\\pi(a|s, \\theta) = \\frac{e^{h(s, a, \\theta)}}{\\sum_{b} e^{h(s, b, \\theta)}}\n",
    "$$\n",
    "\n",
    "donde:\n",
    "$$\n",
    "h(s, a, \\theta)\n",
    "$$ \n",
    "\n",
    "es una **preferencia parametrizable** que puede ser lineal:\n",
    "\n",
    "$$\n",
    "h(s, a, \\theta) = \\theta_a^T s\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805f48dc",
   "metadata": {},
   "source": [
    "Además, el espacio de estados es continuo, con los siguientes valores:\n",
    "\n",
    "| Estado        | Descripción                       | Mínimo | Máximo |\n",
    "|---------------|-----------------------------------|--------|--------|\n",
    "| Cart Position | Posición del carro                | -4.8   | 4.8    |\n",
    "| Cart Velocity | Velocidad del carro               | -Inf   | Inf    |\n",
    "| Pole Angle    | Ángulo del poste                 | -24°   | 24°    |\n",
    "| Pole Velocity | Velocidad angular del poste       | -Inf   | Inf    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5f72970",
   "metadata": {},
   "outputs": [],
   "source": [
    "S = env.observation_space\n",
    "A = env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba1c8963",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_len = S.shape[0]\n",
    "A_len = A.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "424b344b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxPolicy:\n",
    "    def __init__(self, W, b):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "\n",
    "    def logits(self, state):\n",
    "        return state @ self.W + self.b\n",
    "\n",
    "    def probs(self, state):\n",
    "        logits = self.logits(state)\n",
    "        exp_logits = np.exp(logits - np.max(logits))\n",
    "        return exp_logits / np.sum(exp_logits)\n",
    "\n",
    "    def sample(self, state):\n",
    "        probs = self.probs(state)\n",
    "        action = rng.choice(A.n, p=probs)\n",
    "        return action, np.log(probs[action])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe635272",
   "metadata": {},
   "source": [
    "### Simulación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e186d328",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.zeros((S_len, A_len))\n",
    "b = np.zeros(A_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25a9b625",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = SoftmaxPolicy(W, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f4b0dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_episode(policy, render=False):\n",
    "    states = []\n",
    "    actions = []\n",
    "    rewards = []\n",
    "    log_probs = []\n",
    "\n",
    "    state, info = env.reset()\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        if render:\n",
    "            img = env.render()\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off')\n",
    "            display(plt.gcf())\n",
    "            clear_output(wait=True)\n",
    "            time.sleep(0.05)\n",
    "\n",
    "        action, log_prob = policy.sample(state)\n",
    "        next_state, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "        states.append(state)\n",
    "        actions.append(action)\n",
    "        rewards.append(reward)\n",
    "        log_probs.append(log_prob)\n",
    "\n",
    "        state = next_state\n",
    "        done = terminated or truncated\n",
    "\n",
    "    return states, actions, rewards, log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3086b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "states, actions, rewards, log_probs = simulate_episode(policy, render=True)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19f6836",
   "metadata": {},
   "source": [
    "### Rendimiento descontado para cada par de estado-acción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a598f7d",
   "metadata": {},
   "source": [
    "Dado que `REINFORCE` se basa en `Monte Carlo`, se usará el rendimiento descontado para cada par de estado-acción como $$G_t$$\n",
    "\n",
    "$$\n",
    "G_t = \\sum_{k=0}^{\\infty} \\gamma^k R_{t+k+1}\n",
    "$$\n",
    "\n",
    "Además, como se ha visto, en estos casos al ser una estimación sin modelo del entorno, se usará la función valor estado-acción $$Q(s,a)$$ como una estimación del valor esperado del rendimiento descontado:\n",
    "\n",
    "$$Q(s,a) \\approx \\mathbb{E}[G_t | S_t=s, A_t=a]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4a729a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_discounted_returns(rewards, gamma=0.99):\n",
    "    n = len(rewards)\n",
    "    discounted_returns = np.zeros(n)\n",
    "    G = 0\n",
    "    for t in reversed(range(n)):\n",
    "        G = rewards[t] + gamma * G\n",
    "        discounted_returns[t] = G\n",
    "\n",
    "    return discounted_returns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb495de",
   "metadata": {},
   "source": [
    "### Actualización de los parámetros de la póliza"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ab28fc",
   "metadata": {},
   "source": [
    "Los parámetros de la póliza se actualizan de acuerdo a la siguiente fórmula:\n",
    "\n",
    "$$\\theta \\leftarrow \\theta + \\alpha \\gamma^t G_t \\left(\\frac{\\nabla_{\\theta} \\pi(A_t|S_t, \\theta)}{\\pi(A_t|S_t, \\theta)}\\right)$$\n",
    "\n",
    "donde: \n",
    "$$\\nabla_{\\theta} \\pi(A_t|S_t, \\theta)$$\n",
    "es la dirección en el espacio de parámetros que maximiza la probabilidad de seleccionar la acción a en el estado s.\n",
    "\n",
    "$$G_t$$\n",
    "escala la magnitud, cuanto mayor sea el rendimiento esperado, mayor será la actualización.\n",
    "\n",
    "$$\\pi(A_t|S_t, \\theta)$$\n",
    "Acciones menos probables generan actualizaciones más grandes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "251ec530",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearValueBaseline:\n",
    "    def __init__(self):\n",
    "        self.w = np.zeros(S.shape[0])\n",
    "        self.b = 0.0\n",
    "\n",
    "    def predict(self, state) -> float:\n",
    "        return np.dot(self.w, state) + self.b\n",
    "\n",
    "    def fit(self, states, targets, lr: float, epochs: int = 1):\n",
    "        states = np.array(states)\n",
    "        targets = np.array(targets)\n",
    "\n",
    "        for _ in range(epochs):\n",
    "            preds = states @ self.w + self.b\n",
    "            errors = preds - targets\n",
    "\n",
    "            grad_w = (2 / len(states)) * (states.T @ errors)\n",
    "            grad_b = (2 / len(states)) * np.sum(errors)\n",
    "\n",
    "            self.w -= lr * grad_w\n",
    "            self.b -= lr * grad_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70ebbd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = LinearValueBaseline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "842450c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = compute_discounted_returns(rewards)\n",
    "values = [baseline.predict(s) for s in states]\n",
    "advantages = returns - values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67abecf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_update(states, actions, advantages, policy, lr):    \n",
    "    grad_W = np.zeros_like(policy.W)\n",
    "    grad_b = np.zeros_like(policy.b)\n",
    "\n",
    "    for t in range(len(states)):\n",
    "        s = states[t]\n",
    "        a = actions[t]\n",
    "        p = policy.probs(s)\n",
    "        \n",
    "        onehot = np.zeros(policy.b.shape)\n",
    "        onehot[a] = 1\n",
    "        \n",
    "        delta = onehot - p\n",
    "        \n",
    "        grad_W += np.outer(s, delta) * advantages[t]\n",
    "        grad_b += delta * advantages[t]\n",
    "\n",
    "    policy.W += lr * grad_W\n",
    "    policy.b += lr * grad_b\n",
    "    \n",
    "    new_policy = SoftmaxPolicy(policy.W.copy(), policy.b.copy())\n",
    "    return new_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae11c9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_policy = policy_update(states, actions, advantages, policy, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70ead37c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "states, actions, rewards, log_probs = simulate_episode(new_policy, render=True)\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
