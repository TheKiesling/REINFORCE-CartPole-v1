{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e542b104",
   "metadata": {},
   "source": [
    "# Policy Gradient Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c69d9856",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import time, matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b0a8e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 327\n",
    "rng = np.random.default_rng(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8ecb42",
   "metadata": {},
   "source": [
    "## REINFORCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32e58bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8b0853",
   "metadata": {},
   "source": [
    "### Póliza Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b146c2",
   "metadata": {},
   "source": [
    "El entorno de CartPole-v1 tiene un espacio de acciones discreto:\n",
    "\n",
    "| Acción | Descripción                       |\n",
    "|--------|-----------------------------------|\n",
    "| 0      | Mover el carro a la izquierda     |\n",
    "| 1      | Mover el carro a la derecha       |\n",
    "\n",
    "Por lo tanto, se usará `softmax` como **póliza parametrizable**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75916907",
   "metadata": {},
   "source": [
    "La función `softmax` parametrizable es:\n",
    "\n",
    "$$\n",
    "\\pi(a|s, \\theta) = \\frac{e^{h(s, a, \\theta)}}{\\sum_{b} e^{h(s, b, \\theta)}}\n",
    "$$\n",
    "\n",
    "donde:\n",
    "$$\n",
    "h(s, a, \\theta)\n",
    "$$ \n",
    "\n",
    "es una **preferencia parametrizable** que puede ser lineal:\n",
    "\n",
    "$$\n",
    "h(s, a, \\theta) = \\theta_a^T s\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805f48dc",
   "metadata": {},
   "source": [
    "Además, el espacio de estados es continuo, con los siguientes valores:\n",
    "\n",
    "| Estado        | Descripción                       | Mínimo | Máximo |\n",
    "|---------------|-----------------------------------|--------|--------|\n",
    "| Cart Position | Posición del carro                | -4.8   | 4.8    |\n",
    "| Cart Velocity | Velocidad del carro               | -Inf   | Inf    |\n",
    "| Pole Angle    | Ángulo del poste                 | -24°   | 24°    |\n",
    "| Pole Velocity | Velocidad angular del poste       | -Inf   | Inf    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5f72970",
   "metadata": {},
   "outputs": [],
   "source": [
    "S = env.observation_space\n",
    "A = env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "424b344b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxPolicy:\n",
    "    def __init__(self):\n",
    "        self.S_len = S.shape[0]\n",
    "        self.A_len = A.n\n",
    "        \n",
    "        self.W = np.zeros((self.S_len, self.A_len))\n",
    "        self.b = np.zeros(self.A_len)\n",
    "\n",
    "    def logits(self, state):\n",
    "        return state @ self.W + self.b\n",
    "\n",
    "    def probs(self, state):\n",
    "        logits = self.logits(state)\n",
    "        exp_logits = np.exp(logits - np.max(logits))\n",
    "        return exp_logits / np.sum(exp_logits)\n",
    "\n",
    "    def sample(self, state):\n",
    "        probs = self.probs(state)\n",
    "        action = rng.choice(self.A_len, p=probs)\n",
    "        return action, np.log(probs[action])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe635272",
   "metadata": {},
   "source": [
    "### Simulación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86599a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = []\n",
    "actions = []\n",
    "rewards = []\n",
    "log_probs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25a9b625",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = SoftmaxPolicy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bde8c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "done = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9236b754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "327"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state, info = env.reset(seed=SEED)\n",
    "env.action_space.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5c22e6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "while not done:\n",
    "    frame = env.render()\n",
    "    plt.imshow(frame); plt.axis('off')\n",
    "    display(plt.gcf()); clear_output(wait=True)\n",
    "    \n",
    "    action, log_prob = policy.sample(state)\n",
    "    next_state, reward, done, truncated, info = env.step(action)\n",
    "    \n",
    "    states.append(state)\n",
    "    actions.append(action)\n",
    "    rewards.append(reward)\n",
    "    log_probs.append(log_prob)\n",
    "    \n",
    "    time.sleep(1/30)\n",
    "\n",
    "    state = next_state\n",
    "    done = done or truncated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3086b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_return = sum(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "392507b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19f6836",
   "metadata": {},
   "source": [
    "### Rendimiento descontado para cada par de estado-acción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a598f7d",
   "metadata": {},
   "source": [
    "Dado que `REINFORCE` se basa en `Monte Carlo`, se usará el rendimiento descontado para cada par de estado-acción como $$G_t$$\n",
    "\n",
    "$$\n",
    "G_t = \\sum_{k=0}^{\\infty} \\gamma^k R_{t+k+1}\n",
    "$$\n",
    "\n",
    "Además, como se ha visto, en estos casos al ser una estimación sin modelo del entorno, se usará la función valor estado-acción $$Q(s,a)$$ como una estimación del valor esperado del rendimiento descontado:\n",
    "\n",
    "$$Q(s,a) \\approx \\mathbb{E}[G_t | S_t=s, A_t=a]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4a729a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_discounted_returns(rewards, gamma=0.99):\n",
    "    n = len(rewards)\n",
    "    discounted_returns = np.zeros(n)\n",
    "    G = 0\n",
    "    for t in reversed(range(n)):\n",
    "        G = rewards[t] + gamma * G\n",
    "        discounted_returns[t] = G\n",
    "    return discounted_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "779ddfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "discounted_return = compute_discounted_returns(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8d92be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13.99416454, 13.12541872, 12.2478977 , 11.36151283, 10.46617457,\n",
       "        9.5617925 ,  8.64827525,  7.72553056,  6.79346521,  5.85198506,\n",
       "        4.90099501,  3.940399  ,  2.9701    ,  1.99      ,  1.        ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discounted_return"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
